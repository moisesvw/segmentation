{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "ROOT_DIR = os.path.abspath('../models/Mask_RCNN')\n",
    "DATA_DIR = '../data'\n",
    "#import mask rcnn\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mrcnn import visualize\n",
    "import scipy.misc\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationConfig(Config):\n",
    "  NAME = \"SegmentationConfig\"\n",
    "  IMAGES_PER_GPU = 2\n",
    "  NUM_CLASSES = 1 + 9 # background + 9\n",
    "  STEPS_PER_EPOCH = 1000 #1000\n",
    "\n",
    "class SegmentationDataset(utils.Dataset):\n",
    "  ALL_CLASSES = [\n",
    "              ('bicycle', 35),\n",
    "              ('bicycle_group', 163),\n",
    "              ('billboard', 86),\n",
    "              ('bridge', 98),\n",
    "              ('building', 97),\n",
    "              ('bus', 39),\n",
    "              ('bus_group', 167),\n",
    "              ('car', 33),\n",
    "              ('car_groups', 161),\n",
    "              ('dustbin', 85),\n",
    "              ('fence', 67),\n",
    "              ('motorbicycle', 34),\n",
    "              ('motorbicycle_group', 162),\n",
    "              ('others', 0),\n",
    "              ('overpass', 100),\n",
    "              ('person', 36),\n",
    "              ('person_group', 164),\n",
    "              ('pole', 82),\n",
    "              ('rider', 37),\n",
    "              ('rider_group', 165),\n",
    "              ('road', 49),\n",
    "              ('road_pile', 66),\n",
    "              ('rover', 1),\n",
    "              ('siderwalk', 50),\n",
    "              ('sky', 17),\n",
    "              ('traffic_cone', 65),\n",
    "              ('traffic_light', 81),\n",
    "              ('traffic_sign', 83),\n",
    "              ('tricycle', 40),\n",
    "              ('tricycle_group', 168),\n",
    "              ('truck', 38),\n",
    "              ('truck_group', 166),\n",
    "              ('tunnel', 99),\n",
    "              ('vegatation', 113),\n",
    "              ('wall', 84)\n",
    "            ]\n",
    "\n",
    "  MAIN_CLASSES = [33, 35, 39, 40, 36, 65, 34, 38, 37]\n",
    "\n",
    "  CLASSES = [ c for c in ALL_CLASSES if c[1] in [33, 35, 39, 40, 36, 65, 34, 38, 37] ]\n",
    "  CLASS_NAME_TO_ID = {}\n",
    "  CLASS_ID_TO_NAME = {}\n",
    "  CLASS_OLD_ID_TO_ID = {}\n",
    "  for i in range( len(CLASSES) ):\n",
    "      c_name = CLASSES[i][0]\n",
    "      old_id = CLASSES[i][1]\n",
    "      new_id = i + 1\n",
    "\n",
    "      CLASS_NAME_TO_ID[c_name] = { 'id': new_id,   'old_id': old_id }\n",
    "      CLASS_ID_TO_NAME[new_id] = { 'name': c_name, 'old_id': old_id }\n",
    "      CLASS_OLD_ID_TO_ID[old_id] = { 'name': c_name, 'id': new_id }\n",
    "\n",
    "  def load_cvpr_images(self, images_paths):\n",
    "    # Add classes\n",
    "    for class_name in self.CLASS_NAME_TO_ID.keys():\n",
    "      self.add_class(\"wad\", self.CLASS_NAME_TO_ID[class_name]['id'], class_name)\n",
    "\n",
    "    for i in range(len(images_paths)):\n",
    "      path = images_paths[i]\n",
    "      image_name = path.split('/')[-1].split('.')[0]\n",
    "      self.add_image(\"wad\", image_id=i, path=path, image_name=image_name)\n",
    "\n",
    "  def load_mask(self, image_id):\n",
    "    image_name = self.image_info[image_id]['image_name']\n",
    "    path = DATA_DIR+\"/train_label/\"+ image_name +\"_instanceIds.png\"\n",
    "    image = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    ids = []\n",
    "\n",
    "    all_instances = np.unique(image)\n",
    "    intances_ids = [ int(x/1000) for x in all_instances ]\n",
    "    intances_ids = np.array([x for x in intances_ids if x in self.MAIN_CLASSES ])\n",
    "\n",
    "    masks_shape = (image.shape[0], image.shape[1], intances_ids.shape[0])\n",
    "    masks = np.zeros(masks_shape, dtype=np.bool)\n",
    "\n",
    "    i_ = 0\n",
    "    for i in range(all_instances.shape[0]):\n",
    "      class_id = int(all_instances[i]/1000)\n",
    "      if self.CLASS_OLD_ID_TO_ID.get(class_id):\n",
    "        ids.append(self.CLASS_OLD_ID_TO_ID[class_id]['id'])\n",
    "        masks[:, :, i_] = (image == all_instances[i])\n",
    "        i_+=1\n",
    "\n",
    "    ids = np.array(ids, dtype=np.int32)\n",
    "    return masks, ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                22\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           SegmentationConfig\n",
      "NUM_CLASSES                    10\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = glob.glob(DATA_DIR+'/train_color/*.jpg')\n",
    "test = glob.glob(DATA_DIR+'/test/*.jpg')\n",
    "X_train, X_val, _, _ = model_selection.train_test_split(train, train, test_size=0.3)\n",
    "config = SegmentationConfig()\n",
    "config.display()\n",
    "dataset_train = SegmentationDataset()\n",
    "dataset_train.load_cvpr_images(X_train)\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_val = SegmentationDataset()\n",
    "dataset_val.load_cvpr_images(X_val)\n",
    "dataset_val.prepare()\n",
    "\n",
    "testset = SegmentationDataset()\n",
    "testset.load_cvpr_images(test)\n",
    "testset.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last()[1], by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /Users/kanna/Sandbox/cvpr2018/segmentation/models/Mask_RCNN/logs/segmentationconfig20180603T1757/mask_rcnn_segmentationconfig_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/kanna/Sandbox/cvpr2018/segmentation/models/Mask_RCNN/mrcnn/model.py\", line 1686, in data_generator\n",
      "    image_index = (image_index + 1) % len(image_ids)\n",
      "ZeroDivisionError: integer division or modulo by zero\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 677, in _data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"/Users/kanna/Sandbox/cvpr2018/segmentation/models/Mask_RCNN/mrcnn/model.py\", line 1796, in data_generator\n",
      "    dataset.image_info[image_id]))\n",
      "  File \"/Users/kanna/Sandbox/cvpr2018/segmentation/models/Mask_RCNN/mrcnn/model.py\", line 1686, in data_generator\n",
      "    image_index = (image_index + 1) % len(image_ids)\n",
      "ZeroDivisionError: integer division or modulo by zero\n",
      "UnboundLocalError: local variable 'image_id' referenced before assignment\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 677, in _data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"/Users/kanna/Sandbox/cvpr2018/segmentation/models/Mask_RCNN/mrcnn/model.py\", line 1796, in data_generator\n",
      "    dataset.image_info[image_id]))\n",
      "UnboundLocalError: local variable 'image_id' referenced before assignment\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kanna/Sandbox/cvpr2018/segmentation/models/Mask_RCNN/mrcnn/model.py\", line 1686, in data_generator\n",
      "    image_index = (image_index + 1) % len(image_ids)\n",
      "ZeroDivisionError: integer division or modulo by zero\n",
      "  File \"/Users/kanna/Sandbox/cvpr2018/segmentation/models/Mask_RCNN/mrcnn/model.py\", line 1686, in data_generator\n",
      "    image_index = (image_index + 1) % len(image_ids)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "ZeroDivisionError: integer division or modulo by zero\n",
      "Traceback (most recent call last):\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 677, in _data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 677, in _data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"/Users/kanna/Sandbox/cvpr2018/segmentation/models/Mask_RCNN/mrcnn/model.py\", line 1796, in data_generator\n",
      "    dataset.image_info[image_id]))\n",
      "UnboundLocalError: local variable 'image_id' referenced before assignment\n",
      "  File \"/Users/kanna/Sandbox/cvpr2018/segmentation/models/Mask_RCNN/mrcnn/model.py\", line 1796, in data_generator\n",
      "    dataset.image_info[image_id]))\n",
      "UnboundLocalError: local variable 'image_id' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'image_id' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9d2ab2158c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             layers='heads')\n\u001b[0m",
      "\u001b[0;32m~/Sandbox/cvpr2018/segmentation/models/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation)\u001b[0m\n\u001b[1;32m   2326\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2328\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2329\u001b[0m         )\n\u001b[1;32m   2330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2192\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2193\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2194\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'image_id' referenced before assignment"
     ]
    }
   ],
   "source": [
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=15, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from  None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-fc523e6a0a09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Provide path to trained weights\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Sandbox/cvpr2018/segmentation/models/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, exclude)\u001b[0m\n\u001b[1;32m   2083\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2085\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2086\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/h5py/_hl/compat.py\u001b[0m in \u001b[0;36mfilename_encode\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mfilenames\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0minformation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \"\"\"\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"win32\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(SegmentationConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()[1]\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Cannot choose from an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fe5f7b725366>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m original_image, image_meta, gt_class_id, gt_bbox, gt_mask =    modellib.load_image_gt(dataset_val, inference_config, \n\u001b[1;32m      3\u001b[0m                            image_id, use_mini_mask=False)\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/random.py\u001b[0m in \u001b[0;36mchoice\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot choose from an empty sequence'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Cannot choose from an empty sequence"
     ]
    }
   ],
   "source": [
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'original_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3fded95c0c04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"original_image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image_meta\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gt_class_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_class_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gt_bbox\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_bbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gt_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'original_image' is not defined"
     ]
    }
   ],
   "source": [
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'original_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-9e3c75a77cbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n\u001b[1;32m      4\u001b[0m                             dataset_val.class_names, r['scores'], ax=get_ax())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'original_image' is not defined"
     ]
    }
   ],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3740ee0a989c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rois'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "r['rois']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'original_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ccc81701a4e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m711\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m883\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m763\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1020\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'original_image' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(original_image[711:883,763:1020, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-4e40ade13893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'masks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m711\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m883\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m763\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1020\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(r['masks'][:, :, 1][711:883,763:1020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset.image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the test data results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-26:\n",
      "Process ForkPoolWorker-23:\n",
      "Process ForkPoolWorker-25:\n",
      "Process ForkPoolWorker-20:\n",
      "Process ForkPoolWorker-19:\n",
      "Process ForkPoolWorker-22:\n",
      "Process ForkPoolWorker-24:\n",
      "Process ForkPoolWorker-21:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/kanna/anaconda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from skimage.io import imsave\n",
    "from multiprocessing import Pool\n",
    "pool = Pool(processes=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_result(r, image_name, image_id):\n",
    "    data = []\n",
    "    for i in range(len(r['scores'])):\n",
    "        mask_idx = i\n",
    "        confidence = r['scores'][i]\n",
    "        label_id = r['class_ids'][i]\n",
    "        mask = r['masks'][:, :, i]\n",
    "        rois = r['rois'][i]\n",
    "\n",
    "        data_point = {}\n",
    "        old_id = testset.CLASS_ID_TO_NAME[label_id]['old_id']\n",
    "        mask_name = DATA_DIR+'/test_masks/'+ image_name + '_' + str(mask_idx) +'.jpg'\n",
    "        imsave(mask_name, mask)\n",
    "\n",
    "        data_point['ImageId'] = image_name\n",
    "        data_point['LabelId'] = old_id\n",
    "        data_point['Confidence'] = confidence\n",
    "        data_point['PixelCount'] = 0\n",
    "        data_point['rois'] = rois\n",
    "        data_point['EncodedPixels'] = mask_name\n",
    "\n",
    "        data.append(data_point)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for all takes: 0.00014162063598632812\n"
     ]
    }
   ],
   "source": [
    "test_results = []\n",
    "jobs = []\n",
    "t3 = time.time()\n",
    "for test_id in testset.image_ids:\n",
    "    if (test_id % 50) == 0:\n",
    "        print(test_id)\n",
    "    results = model.detect([testset.load_image(test_id)], verbose=0)\n",
    "    r = results[0]\n",
    "\n",
    "    image_name = testset.image_info[test_id]['image_name']\n",
    "\n",
    "    p_result = pool.apply_async(process_result, (r, image_name, test_id) )\n",
    "    jobs.append(p_result)\n",
    "\n",
    "for job in jobs:\n",
    "    p_result = job.get(timeout=20)\n",
    "    test_results = test_results + p_result\n",
    "t3_ = time.time()\n",
    "print(\"Time for all takes:\", t3_ - t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-999f3d15af6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_results\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(len(test_results) )\n",
    "test_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_results = pd.DataFrame(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>LabelId</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>PixelCount</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>rois</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56dbd8514bd2b8d1566f8977cfeb0406</td>\n",
       "      <td>33</td>\n",
       "      <td>0.999186</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/ubuntu/datalab/test_masks/56dbd8514bd2b8...</td>\n",
       "      <td>[1911 2476 2425 3219]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56dbd8514bd2b8d1566f8977cfeb0406</td>\n",
       "      <td>33</td>\n",
       "      <td>0.998902</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/ubuntu/datalab/test_masks/56dbd8514bd2b8...</td>\n",
       "      <td>[1773 2146 1861 2412]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56dbd8514bd2b8d1566f8977cfeb0406</td>\n",
       "      <td>33</td>\n",
       "      <td>0.998630</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/ubuntu/datalab/test_masks/56dbd8514bd2b8...</td>\n",
       "      <td>[1783 2775 1850 2903]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56dbd8514bd2b8d1566f8977cfeb0406</td>\n",
       "      <td>33</td>\n",
       "      <td>0.998304</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/ubuntu/datalab/test_masks/56dbd8514bd2b8...</td>\n",
       "      <td>[1791 2936 1881 3078]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56dbd8514bd2b8d1566f8977cfeb0406</td>\n",
       "      <td>33</td>\n",
       "      <td>0.993302</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/ubuntu/datalab/test_masks/56dbd8514bd2b8...</td>\n",
       "      <td>[1679    6 1755  197]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ImageId  LabelId  Confidence  PixelCount  \\\n",
       "0  56dbd8514bd2b8d1566f8977cfeb0406       33    0.999186           0   \n",
       "1  56dbd8514bd2b8d1566f8977cfeb0406       33    0.998902           0   \n",
       "2  56dbd8514bd2b8d1566f8977cfeb0406       33    0.998630           0   \n",
       "3  56dbd8514bd2b8d1566f8977cfeb0406       33    0.998304           0   \n",
       "4  56dbd8514bd2b8d1566f8977cfeb0406       33    0.993302           0   \n",
       "\n",
       "                                       EncodedPixels                   rois  \n",
       "0  /home/ubuntu/datalab/test_masks/56dbd8514bd2b8...  [1911 2476 2425 3219]  \n",
       "1  /home/ubuntu/datalab/test_masks/56dbd8514bd2b8...  [1773 2146 1861 2412]  \n",
       "2  /home/ubuntu/datalab/test_masks/56dbd8514bd2b8...  [1783 2775 1850 2903]  \n",
       "3  /home/ubuntu/datalab/test_masks/56dbd8514bd2b8...  [1791 2936 1881 3078]  \n",
       "4  /home/ubuntu/datalab/test_masks/56dbd8514bd2b8...  [1679    6 1755  197]  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_results = pd.read_csv(DATA_DIR+'/test_results.csv')\n",
    "df_test_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['ImageId','LabelId','PixelCount','Confidence','EncodedPixels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_results.to_csv(DATA_DIR+'/submit_test_.csv',index=False, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=cv2.imread(DATA_DIR+'/test_masks/4e3c95fe41cce1072ccbb69e8a1a20fb_4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167448"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c7e3fbc18>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6567a7d0f125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'masks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "r['masks'][:, :, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be non-empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-917e5b9c36e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Compute VOC-Style mAP @ IoU=0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Running on 10 images. Increase for better accuracy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimage_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mAPs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be non-empty"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 711,  422,  928,  894],\n",
       "       [ 685,  826,  748, 1004],\n",
       "       [ 629,  222,  648,  243],\n",
       "       [ 647,  507,  679,  569],\n",
       "       [ 641,  447,  656,  474],\n",
       "       [ 645,  501,  670,  530],\n",
       "       [ 643,  503,  654,  530],\n",
       "       [ 641,  482,  660,  499]], dtype=int32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[\"rois\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 3, 3], dtype=int32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[\"class_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9969446 , 0.9946017 , 0.992332  , 0.83706295, 0.8179433 ,\n",
       "       0.81449354, 0.7057352 , 0.7026884 ], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[\"scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_ids': array([3, 3, 3, 9, 3, 3, 3, 9, 3, 3, 3, 3], dtype=int32),\n",
       " 'masks': array([[[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       " \n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       " \n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       " \n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       " \n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]]]),\n",
       " 'rois': array([[ 673,  169,  811,  318],\n",
       "        [ 637,  245,  669,  281],\n",
       "        [ 631,  232,  642,  247],\n",
       "        [ 609,  396,  770,  613],\n",
       "        [ 662,  676,  686,  726],\n",
       "        [ 667,  794,  693,  875],\n",
       "        [ 670,  722,  690,  773],\n",
       "        [ 659,  623,  704,  669],\n",
       "        [ 695,  897,  719, 1019],\n",
       "        [ 634,  246,  652,  272],\n",
       "        [ 631,  252,  641,  269],\n",
       "        [ 668,  742,  679,  773]], dtype=int32),\n",
       " 'scores': array([0.9997043 , 0.9990097 , 0.99800783, 0.99118984, 0.9618015 ,\n",
       "        0.9240078 , 0.8525393 , 0.84261686, 0.8122865 , 0.7743808 ,\n",
       "        0.7340564 , 0.7180881 ], dtype=float32)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submision File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageId                           24e40595388f15dcaa2a2dee8bcb4d26\n",
       "LabelId                                                         33\n",
       "Confidence                                                0.813742\n",
       "PixelCount                                                       0\n",
       "EncodedPixels    /home/ubuntu/datalab/test_masks/24e40595388f15...\n",
       "rois                                         [1710  901 1811 1027]\n",
       "Name: 200, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = df_test_results.ix[200]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = d['EncodedPixels'].split('/')[-1]\n",
    "mask_im = cv2.imread(DATA_DIR+'/test_masks/'+mask_path, cv2.IMREAD_UNCHANGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_bound = [ int(x) for x in d.rois.replace(\"[\", \"\").replace(\"]\", \"\").split() ]\n",
    "mask = mask_im[mask_bound[0]:mask_bound[2], mask_bound[1]:mask_bound[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 113)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mask*255)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pixels(mask):\n",
    "    endcoded_pixels = []\n",
    "    total_pixels = 0\n",
    "    for i in range(mask.shape[0]):\n",
    "        init = 0\n",
    "        end = 0\n",
    "        carry = i*mask.shape[1]\n",
    "        for j in range(1, mask.shape[1]):\n",
    "            if mask[i, j] > 0 and mask[i, j - 1] == 0:\n",
    "                init = j + carry\n",
    "\n",
    "            if mask[i, j] == 0 and mask[i, j - 1] > 0:\n",
    "                end = j-init + carry\n",
    "                endcoded_pixels.append( str(init) + ' ' +  str(end) ) \n",
    "                total_pixels += end\n",
    "                init = 0\n",
    "                end = 0\n",
    "\n",
    "    return endcoded_pixels, total_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodp, _ = find_pixels(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'373 8|486 8|591 40|704 40|817 40|922 80|1035 80|1148 80|1261 80|1374 80|1487 80|1600 80|1713 80|1818 88|1931 88|2044 88|2157 88|2270 88|2383 88|2496 88|2609 88|2722 96|2835 96|2948 96|3061 96|3174 96|3287 96|3400 96|3513 96|3621 101|3734 101|3847 101|3960 101|4073 101|4186 101|4299 101|4412 101|4522 104|4635 104|4748 104|4861 104|4974 104|5087 104|5200 104|5313 104|5426 104|5539 104|5652 104|5765 104|5878 104|5991 104|6104 104|6217 104|6330 104|6443 104|6556 104|6669 104|6782 104|6895 104|7008 104|7121 104|7234 104|7347 104|7460 104|7573 104|7686 104|7799 104|7912 104|8025 104|8138 104|8251 104|8364 104|8477 104|8590 104|8703 104|8816 104|8929 104|9042 24|9114 32|9155 24|9227 32|9268 24|9340 32|9381 24|9461 24|9494 24|9574 24|9607 16|9687 24|9720 16|9800 24|9833 16|9913 24|10034 8|10147 8|10260 8|'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"|\".join(encodp) + \"|\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20328, 6)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_results['PixelCount'][3]\n",
    "df_test_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-b490cc100c69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmask_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/test_masks/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmask_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_UNCHANGED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmask_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrois\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_im\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_bound\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmask_bound\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_bound\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmask_bound\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mencoded_pixels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixels_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_pixels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mencoded_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"|\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_pixels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"|\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# for i in range(2):\n",
    "for i in range(df_test_results.shape[0]):\n",
    "    d = df_test_results.ix[i]\n",
    "    mask_path = d['EncodedPixels'].split('/')[-1]\n",
    "    mask_im = cv2.imread(DATA_DIR+'/test_masks/'+mask_path, cv2.IMREAD_UNCHANGED)\n",
    "    mask_bound = [ int(x) for x in d.rois.replace(\"[\", \"\").replace(\"]\", \"\").split() ]\n",
    "    mask = mask_im[mask_bound[0]:mask_bound[2], mask_bound[1]:mask_bound[3]]\n",
    "    encoded_pixels, pixels_count = find_pixels(mask)\n",
    "    encoded_pixels = \"|\".join(encoded_pixels) + \"|\"\n",
    "    df_test_results['PixelCount'][i] = pixels_count\n",
    "    df_test_results['EncodedPixels'][i] = encoded_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>LabelId</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>PixelCount</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>rois</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56dbd8514bd2b8d1566f8977cfeb0406</td>\n",
       "      <td>33</td>\n",
       "      <td>0.999186</td>\n",
       "      <td>280072</td>\n",
       "      <td>3288 72|4031 72|4734 144|5477 144|6220 144|689...</td>\n",
       "      <td>[1911 2476 2425 3219]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56dbd8514bd2b8d1566f8977cfeb0406</td>\n",
       "      <td>33</td>\n",
       "      <td>0.998902</td>\n",
       "      <td>16432</td>\n",
       "      <td>884 104|1150 104|1416 104|1682 112|1948 112|22...</td>\n",
       "      <td>[1773 2146 1861 2412]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56dbd8514bd2b8d1566f8977cfeb0406</td>\n",
       "      <td>33</td>\n",
       "      <td>0.998630</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/ubuntu/datalab/test_masks/56dbd8514bd2b8...</td>\n",
       "      <td>[1783 2775 1850 2903]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56dbd8514bd2b8d1566f8977cfeb0406</td>\n",
       "      <td>33</td>\n",
       "      <td>0.998304</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/ubuntu/datalab/test_masks/56dbd8514bd2b8...</td>\n",
       "      <td>[1791 2936 1881 3078]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56dbd8514bd2b8d1566f8977cfeb0406</td>\n",
       "      <td>33</td>\n",
       "      <td>0.993302</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/ubuntu/datalab/test_masks/56dbd8514bd2b8...</td>\n",
       "      <td>[1679    6 1755  197]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ImageId  LabelId  Confidence  PixelCount  \\\n",
       "0  56dbd8514bd2b8d1566f8977cfeb0406       33    0.999186      280072   \n",
       "1  56dbd8514bd2b8d1566f8977cfeb0406       33    0.998902       16432   \n",
       "2  56dbd8514bd2b8d1566f8977cfeb0406       33    0.998630           0   \n",
       "3  56dbd8514bd2b8d1566f8977cfeb0406       33    0.998304           0   \n",
       "4  56dbd8514bd2b8d1566f8977cfeb0406       33    0.993302           0   \n",
       "\n",
       "                                       EncodedPixels                   rois  \n",
       "0  3288 72|4031 72|4734 144|5477 144|6220 144|689...  [1911 2476 2425 3219]  \n",
       "1  884 104|1150 104|1416 104|1682 112|1948 112|22...  [1773 2146 1861 2412]  \n",
       "2  /home/ubuntu/datalab/test_masks/56dbd8514bd2b8...  [1783 2775 1850 2903]  \n",
       "3  /home/ubuntu/datalab/test_masks/56dbd8514bd2b8...  [1791 2936 1881 3078]  \n",
       "4  /home/ubuntu/datalab/test_masks/56dbd8514bd2b8...  [1679    6 1755  197]  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_function(i):\n",
    "    d = df_test_results.iloc[i]\n",
    "    mask_path = d['EncodedPixels'].split('/')[-1]\n",
    "    mask_im = cv2.imread(DATA_DIR+'/test_masks/'+mask_path, cv2.IMREAD_UNCHANGED)\n",
    "    mask_bound = [ int(x) for x in d.rois.replace(\"[\", \"\").replace(\"]\", \"\").split() ]\n",
    "    mask = mask_im[mask_bound[0]:mask_bound[2], mask_bound[1]:mask_bound[3]]\n",
    "    encoded_pixels, pixels_count = find_pixels(mask)\n",
    "    encoded_pixels = \"|\".join(encoded_pixels) + \"|\"\n",
    "#     df_test_results['PixelCount'][i] = pixels_count\n",
    "#     df_test_results['EncodedPixels'][i] = encoded_pixels\n",
    "#     print(df_test_results.ix[i])\n",
    "    with open('my_csv.csv', 'a') as f:\n",
    "        #df_test_results.ix[i].to_csv(f, header=False)\n",
    "        #pd.DataFrame(df_test_results.iloc[i]).to_csv(f, header=False)\n",
    "        f.write(str(i) + ',' + str(df_test_results.iloc[i]['ImageId']) + ',' + str(df_test_results.iloc[i]['LabelId']) + ',' + str(df_test_results.iloc[i]['Confidence']) + ',' + str(pixels_count) + ',' + str(encoded_pixels) + ',' + str(df_test_results.iloc[i]['rois']))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(8)\n",
    "zip(pool.map(result_function, range(0, df_test_results.shape[0])))\n",
    "pool.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
