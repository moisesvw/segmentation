{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "ROOT_DIR = os.path.abspath('../models/Mask_RCNN')\n",
    "DATA_DIR = '../data'\n",
    "#import mask rcnn\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mrcnn import visualize\n",
    "import scipy.misc\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationConfig(Config):\n",
    "  NAME = \"SegmentationConfig\"\n",
    "  IMAGES_PER_GPU = 2\n",
    "  NUM_CLASSES = 1 + 9 # background + 9\n",
    "  STEPS_PER_EPOCH = 1000 #1000\n",
    "\n",
    "class SegmentationDataset(utils.Dataset):\n",
    "  ALL_CLASSES = [\n",
    "              ('bicycle', 35),\n",
    "              ('bicycle_group', 163),\n",
    "              ('billboard', 86),\n",
    "              ('bridge', 98),\n",
    "              ('building', 97),\n",
    "              ('bus', 39),\n",
    "              ('bus_group', 167),\n",
    "              ('car', 33),\n",
    "              ('car_groups', 161),\n",
    "              ('dustbin', 85),\n",
    "              ('fence', 67),\n",
    "              ('motorbicycle', 34),\n",
    "              ('motorbicycle_group', 162),\n",
    "              ('others', 0),\n",
    "              ('overpass', 100),\n",
    "              ('person', 36),\n",
    "              ('person_group', 164),\n",
    "              ('pole', 82),\n",
    "              ('rider', 37),\n",
    "              ('rider_group', 165),\n",
    "              ('road', 49),\n",
    "              ('road_pile', 66),\n",
    "              ('rover', 1),\n",
    "              ('siderwalk', 50),\n",
    "              ('sky', 17),\n",
    "              ('traffic_cone', 65),\n",
    "              ('traffic_light', 81),\n",
    "              ('traffic_sign', 83),\n",
    "              ('tricycle', 40),\n",
    "              ('tricycle_group', 168),\n",
    "              ('truck', 38),\n",
    "              ('truck_group', 166),\n",
    "              ('tunnel', 99),\n",
    "              ('vegatation', 113),\n",
    "              ('wall', 84)\n",
    "            ]\n",
    "\n",
    "  MAIN_CLASSES = [33, 35, 39, 40, 36, 65, 34, 38, 37]\n",
    "\n",
    "  CLASSES = [ c for c in ALL_CLASSES if c[1] in [33, 35, 39, 40, 36, 65, 34, 38, 37] ]\n",
    "  CLASS_NAME_TO_ID = {}\n",
    "  CLASS_ID_TO_NAME = {}\n",
    "  CLASS_OLD_ID_TO_ID = {}\n",
    "  for i in range( len(CLASSES) ):\n",
    "      c_name = CLASSES[i][0]\n",
    "      old_id = CLASSES[i][1]\n",
    "      new_id = i + 1\n",
    "\n",
    "      CLASS_NAME_TO_ID[c_name] = { 'id': new_id,   'old_id': old_id }\n",
    "      CLASS_ID_TO_NAME[new_id] = { 'name': c_name, 'old_id': old_id }\n",
    "      CLASS_OLD_ID_TO_ID[old_id] = { 'name': c_name, 'id': new_id }\n",
    "\n",
    "  def load_cvpr_images(self, images_paths):\n",
    "    # Add classes\n",
    "    for class_name in self.CLASS_NAME_TO_ID.keys():\n",
    "      self.add_class(\"wad\", self.CLASS_NAME_TO_ID[class_name]['id'], class_name)\n",
    "\n",
    "    for i in range(len(images_paths)):\n",
    "      path = images_paths[i]\n",
    "      image_name = path.split('/')[-1].split('.')[0]\n",
    "      self.add_image(\"wad\", image_id=i, path=path, image_name=image_name)\n",
    "\n",
    "  def load_mask(self, image_id):\n",
    "    image_name = self.image_info[image_id]['image_name']\n",
    "    path = DATA_DIR+\"/train_label/\"+ image_name +\"_instanceIds.png\"\n",
    "    image = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    ids = []\n",
    "\n",
    "    all_instances = np.unique(image)\n",
    "    intances_ids = [ int(x/1000) for x in all_instances ]\n",
    "    intances_ids = np.array([x for x in intances_ids if x in self.MAIN_CLASSES ])\n",
    "\n",
    "    masks_shape = (image.shape[0], image.shape[1], intances_ids.shape[0])\n",
    "    masks = np.zeros(masks_shape, dtype=np.bool)\n",
    "\n",
    "    i_ = 0\n",
    "    for i in range(all_instances.shape[0]):\n",
    "      class_id = int(all_instances[i]/1000)\n",
    "      if self.CLASS_OLD_ID_TO_ID.get(class_id):\n",
    "        ids.append(self.CLASS_OLD_ID_TO_ID[class_id]['id'])\n",
    "        masks[:, :, i_] = (image == all_instances[i])\n",
    "        i_+=1\n",
    "\n",
    "    ids = np.array(ids, dtype=np.int32)\n",
    "    return masks, ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = glob.glob(DATA_DIR+'/train_color/*.jpg')\n",
    "test = glob.glob(DATA_DIR+'/test/*.jpg')\n",
    "X_train, X_val, _, _ = model_selection.train_test_split(train, train, test_size=0.3)\n",
    "config = SegmentationConfig()\n",
    "config.display()\n",
    "dataset_train = SegmentationDataset()\n",
    "dataset_train.load_cvpr_images(X_train)\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_val = SegmentationDataset()\n",
    "dataset_val.load_cvpr_images(X_val)\n",
    "dataset_val.prepare()\n",
    "\n",
    "testset = SegmentationDataset()\n",
    "testset.load_cvpr_images(test)\n",
    "testset.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last()[1], by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=15, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(SegmentationConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()[1]\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['rois']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(original_image[711:883,763:1020, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(r['masks'][:, :, 1][711:883,763:1020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testset.image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the test data results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imsave\n",
    "from multiprocessing import Pool\n",
    "pool = Pool(processes=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_result(r, image_name, image_id):\n",
    "    data = []\n",
    "    for i in range(len(r['scores'])):\n",
    "        mask_idx = i\n",
    "        confidence = r['scores'][i]\n",
    "        label_id = r['class_ids'][i]\n",
    "        mask = r['masks'][:, :, i]\n",
    "        rois = r['rois'][i]\n",
    "\n",
    "        data_point = {}\n",
    "        old_id = testset.CLASS_ID_TO_NAME[label_id]['old_id']\n",
    "        mask_name = DATA_DIR+'/test_masks/'+ image_name + '_' + str(mask_idx) +'.jpg'\n",
    "        imsave(mask_name, mask)\n",
    "\n",
    "        data_point['ImageId'] = image_name\n",
    "        data_point['LabelId'] = old_id\n",
    "        data_point['Confidence'] = confidence\n",
    "        data_point['PixelCount'] = 0\n",
    "        data_point['rois'] = rois\n",
    "        data_point['EncodedPixels'] = mask_name\n",
    "\n",
    "        data.append(data_point)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []\n",
    "jobs = []\n",
    "t3 = time.time()\n",
    "for test_id in testset.image_ids:\n",
    "    if (test_id % 50) == 0:\n",
    "        print(test_id)\n",
    "    results = model.detect([testset.load_image(test_id)], verbose=0)\n",
    "    r = results[0]\n",
    "\n",
    "    image_name = testset.image_info[test_id]['image_name']\n",
    "\n",
    "    p_result = pool.apply_async(process_result, (r, image_name, test_id) )\n",
    "    jobs.append(p_result)\n",
    "\n",
    "for job in jobs:\n",
    "    p_result = job.get(timeout=20)\n",
    "    test_results = test_results + p_result\n",
    "t3_ = time.time()\n",
    "print(\"Time for all takes:\", t3_ - t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_results) )\n",
    "test_results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_results = pd.DataFrame(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_results = pd.read_csv(DATA_DIR+'/test_results.csv')\n",
    "df_test_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['ImageId','LabelId','PixelCount','Confidence','EncodedPixels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_results.to_csv(DATA_DIR+'/submit_test_.csv',index=False, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=cv2.imread(DATA_DIR+'/test_masks/4e3c95fe41cce1072ccbb69e8a1a20fb_4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['masks'][:, :, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[\"rois\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[\"class_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[\"scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submision File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df_test_results.ix[200]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = d['EncodedPixels'].split('/')[-1]\n",
    "mask_im = cv2.imread(DATA_DIR+'/test_masks/'+mask_path, cv2.IMREAD_UNCHANGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_bound = [ int(x) for x in d.rois.replace(\"[\", \"\").replace(\"]\", \"\").split() ]\n",
    "mask = mask_im[mask_bound[0]:mask_bound[2], mask_bound[1]:mask_bound[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask*255)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pixels(mask):\n",
    "    endcoded_pixels = []\n",
    "    total_pixels = 0\n",
    "    for i in range(mask.shape[0]):\n",
    "        init = 0\n",
    "        end = 0\n",
    "        carry = i*mask.shape[1]\n",
    "        for j in range(1, mask.shape[1]):\n",
    "            if mask[i, j] > 0 and mask[i, j - 1] == 0:\n",
    "                init = j + carry\n",
    "\n",
    "            if mask[i, j] == 0 and mask[i, j - 1] > 0:\n",
    "                end = j-init + carry\n",
    "                endcoded_pixels.append( str(init) + ' ' +  str(end) ) \n",
    "                total_pixels += end\n",
    "                init = 0\n",
    "                end = 0\n",
    "\n",
    "    return endcoded_pixels, total_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodp, _ = find_pixels(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"|\".join(encodp) + \"|\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_results['PixelCount'][3]\n",
    "df_test_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(2):\n",
    "for i in range(df_test_results.shape[0]):\n",
    "    d = df_test_results.ix[i]\n",
    "    mask_path = d['EncodedPixels'].split('/')[-1]\n",
    "    mask_im = cv2.imread(DATA_DIR+'/test_masks/'+mask_path, cv2.IMREAD_UNCHANGED)\n",
    "    mask_bound = [ int(x) for x in d.rois.replace(\"[\", \"\").replace(\"]\", \"\").split() ]\n",
    "    mask = mask_im[mask_bound[0]:mask_bound[2], mask_bound[1]:mask_bound[3]]\n",
    "    encoded_pixels, pixels_count = find_pixels(mask)\n",
    "    encoded_pixels = \"|\".join(encoded_pixels) + \"|\"\n",
    "    df_test_results['PixelCount'][i] = pixels_count\n",
    "    df_test_results['EncodedPixels'][i] = encoded_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the csv header\n",
    "with open('my_csv.csv', 'a') as f:\n",
    "    f.write('ImageId,LabelId,Confidence,PixelCount,EncodedPixels')\n",
    "    f.write('\\n')\n",
    "    \n",
    "#abstract the function\n",
    "def result_function(i):\n",
    "    d = df_test_results.iloc[i]\n",
    "    mask_path = d['EncodedPixels'].split('/')[-1]\n",
    "    mask_im = cv2.imread(DATA_DIR+'/test_masks/'+mask_path, cv2.IMREAD_UNCHANGED)\n",
    "    mask_bound = [ int(x) for x in d.rois.replace(\"[\", \"\").replace(\"]\", \"\").split() ]\n",
    "    mask = mask_im[mask_bound[0]:mask_bound[2], mask_bound[1]:mask_bound[3]]\n",
    "    encoded_pixels, pixels_count = find_pixels(mask)\n",
    "    encoded_pixels = \"|\".join(encoded_pixels) + \"|\"\n",
    "#     df_test_results['PixelCount'][i] = pixels_count\n",
    "#     df_test_results['EncodedPixels'][i] = encoded_pixels\n",
    "#     print(df_test_results.ix[i])\n",
    "    with open('my_csv.csv', 'a') as f:\n",
    "        #df_test_results.ix[i].to_csv(f, header=False)\n",
    "        #pd.DataFrame(df_test_results.iloc[i]).to_csv(f, header=False)\n",
    "        f.write(str(i) + ',' + str(df_test_results.iloc[i]['ImageId']) + ',' + str(df_test_results.iloc[i]['LabelId']) + ',' + str(df_test_results.iloc[i]['Confidence']) + ',' + str(pixels_count) + ',' + str(encoded_pixels))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(8)\n",
    "zip(pool.map(result_function, range(0, df_test_results.shape[0])))\n",
    "pool.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
